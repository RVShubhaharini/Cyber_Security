{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4059918,"sourceType":"datasetVersion","datasetId":2398189,"isSourceIdPinned":false},{"sourceId":14092556,"sourceType":"datasetVersion","datasetId":8973728}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/heart-attack-new/heart_attack_russia_youth_vs_adult.csv\")\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T14:40:06.504681Z","iopub.execute_input":"2025-12-10T14:40:06.504908Z","iopub.status.idle":"2025-12-10T14:40:08.785872Z","shell.execute_reply.started":"2025-12-10T14:40:06.504887Z","shell.execute_reply":"2025-12-10T14:40:08.784922Z"}},"outputs":[{"name":"stdout","text":"Index(['ID', 'Age', 'Gender', 'Region', 'Blood_Pressure', 'Cholesterol', 'BMI',\n       'Heart_Rate', 'Exercise_Level', 'Smoking', 'Alcohol_Consumption',\n       'Diabetes', 'Family_History', 'Stress_Level', 'Heart_Attack', 'Angina',\n       'Heart_Disease_History', 'Diet', 'Sleep_Hours', 'Occupation',\n       'Income_Level', 'Physical_Activity', 'Education_Level',\n       'Marital_Status', 'Urban_Rural', 'Medication', 'Health_Awareness',\n       'Daily_Water_Intake', 'Mental_Health', 'Obesity'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df[\"Heart_Attack\"].unique()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T14:41:01.826657Z","iopub.execute_input":"2025-12-10T14:41:01.827417Z","iopub.status.idle":"2025-12-10T14:41:01.840878Z","shell.execute_reply.started":"2025-12-10T14:41:01.827385Z","shell.execute_reply":"2025-12-10T14:41:01.840051Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"array([False,  True])"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\n\n# -------------------------------\n# 1. Load dataset\n# -------------------------------\ndf = pd.read_csv(\"/kaggle/input/heart-attack-new/heart_attack_russia_youth_vs_adult.csv\")\nprint(\"Initial shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())\n\n# -------------------------------\n# 2. Convert target column True/False ‚Üí 1/0\n# -------------------------------\nif df[\"Heart_Attack\"].dtype == bool or df[\"Heart_Attack\"].dtype == object:\n    df[\"Heart_Attack\"] = df[\"Heart_Attack\"].map({True: 1, False: 0}).astype(int)\n\nprint(\"\\nUnique values in Heart_Attack:\", df[\"Heart_Attack\"].unique())\n\n# -------------------------------\n# 3. Drop useless columns (if needed)\n# -------------------------------\nif \"ID\" in df.columns:\n    df = df.drop(\"ID\", axis=1)\n\n# -------------------------------\n# 4. Detect numeric and categorical columns\n# -------------------------------\nnum_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\ncat_cols = df.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n\n# Remove target from lists\nif \"Heart_Attack\" in num_cols:\n    num_cols.remove(\"Heart_Attack\")\n\nprint(\"\\nNumeric columns:\", num_cols)\nprint(\"Categorical columns:\", cat_cols)\n\n# -------------------------------\n# 5. Handle missing values\n# -------------------------------\n# Numeric fill with median\nif len(num_cols) > 0:\n    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Categorical fill with mode\nfor col in cat_cols:\n    if df[col].isnull().any():\n        df[col] = df[col].fillna(df[col].mode()[0])\n\n# -------------------------------\n# 6. Encode categorical columns\n# -------------------------------\nle = LabelEncoder()\nfor col in cat_cols:\n    df[col] = le.fit_transform(df[col].astype(str))\n\n# -------------------------------\n# 7. Scale numeric columns\n# -------------------------------\nscaler = MinMaxScaler()\nif len(num_cols) > 0:\n    df[num_cols] = scaler.fit_transform(df[num_cols])\n\n# -------------------------------\n# 8. Final output\n# -------------------------------\noutput_path = \"/kaggle/working/heart_attack_cleaned.csv\"\ndf.to_csv(output_path, index=False)\n\nprint(\"\\n‚úÖ Preprocessing Complete!\")\nprint(\"üìÅ Saved as:\", output_path)\nprint(\"Final Shape:\", df.shape)\nprint(\"Target distribution:\")\nprint(df[\"Heart_Attack\"].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T14:43:41.454120Z","iopub.execute_input":"2025-12-10T14:43:41.454948Z","iopub.status.idle":"2025-12-10T14:43:43.594427Z","shell.execute_reply.started":"2025-12-10T14:43:41.454916Z","shell.execute_reply":"2025-12-10T14:43:43.593554Z"}},"outputs":[{"name":"stdout","text":"Initial shape: (50000, 30)\nColumns: ['ID', 'Age', 'Gender', 'Region', 'Blood_Pressure', 'Cholesterol', 'BMI', 'Heart_Rate', 'Exercise_Level', 'Smoking', 'Alcohol_Consumption', 'Diabetes', 'Family_History', 'Stress_Level', 'Heart_Attack', 'Angina', 'Heart_Disease_History', 'Diet', 'Sleep_Hours', 'Occupation', 'Income_Level', 'Physical_Activity', 'Education_Level', 'Marital_Status', 'Urban_Rural', 'Medication', 'Health_Awareness', 'Daily_Water_Intake', 'Mental_Health', 'Obesity']\n\nUnique values in Heart_Attack: [0 1]\n\nNumeric columns: ['Age', 'Blood_Pressure', 'Cholesterol', 'BMI', 'Heart_Rate', 'Stress_Level', 'Sleep_Hours', 'Health_Awareness', 'Daily_Water_Intake', 'Mental_Health']\nCategorical columns: ['Gender', 'Region', 'Exercise_Level', 'Smoking', 'Alcohol_Consumption', 'Diabetes', 'Family_History', 'Angina', 'Heart_Disease_History', 'Diet', 'Occupation', 'Income_Level', 'Physical_Activity', 'Education_Level', 'Marital_Status', 'Urban_Rural', 'Medication', 'Obesity']\n\n‚úÖ Preprocessing Complete!\nüìÅ Saved as: /kaggle/working/heart_attack_cleaned.csv\nFinal Shape: (50000, 29)\nTarget distribution:\nHeart_Attack\n0    44119\n1     5881\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# -----------------------------\n# 1Ô∏è‚É£ Load your dataset\n# -----------------------------\ndf = pd.read_csv(\"/kaggle/working/heart_attack_smoted.csv\")  # change file if needed\n\nTARGET = \"Heart_Attack\"   # <-- change if your target column is different\n\nX = df.drop(TARGET, axis=1)\ny = df[TARGET].astype(int)\n\nprint(\"Original dimension:\", X.shape[1])\n\n# -----------------------------\n# 2Ô∏è‚É£ Train-test split\n# -----------------------------\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.20, stratify=y, random_state=42\n)\n\n# -----------------------------\n# 3Ô∏è‚É£ XGBoost Model (500 Iterations)\n# -----------------------------\nmodel = XGBClassifier(\n    n_estimators=500,          # <-- 500 boosting rounds\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    objective=\"binary:logistic\",\n    eval_metric=\"logloss\",\n    random_state=42,\n    n_jobs=-1\n)\n\nmodel.fit(X_train, y_train)\n\n# -----------------------------\n# 4Ô∏è‚É£ Predictions\n# -----------------------------\ny_pred = model.predict(X_test)\n\ntest_acc = accuracy_score(y_test, y_pred)\ntest_prec = precision_score(y_test, y_pred, zero_division=0)\ntest_rec = recall_score(y_test, y_pred, zero_division=0)\ntest_f1 = f1_score(y_test, y_pred, zero_division=0)\n\n# -----------------------------\n# 5Ô∏è‚É£ Results\n# -----------------------------\nprint(\"\\n===== XGBoost Results (500 Iterations) =====\")\nprint(f\"Test Accuracy : {test_acc:.8f}\")\nprint(f\"Precision     : {test_prec:.8f}\")\nprint(f\"Recall        : {test_rec:.8f}\")\nprint(f\"F1 Score      : {test_f1:.8f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T15:01:01.217743Z","iopub.execute_input":"2025-12-10T15:01:01.218178Z","iopub.status.idle":"2025-12-10T15:01:04.288948Z","shell.execute_reply.started":"2025-12-10T15:01:01.218153Z","shell.execute_reply":"2025-12-10T15:01:04.288115Z"}},"outputs":[{"name":"stdout","text":"Original dimension: 28\n\n===== XGBoost Results (500 Iterations) =====\nTest Accuracy : 0.92628060\nPrecision     : 1.00000000\nRecall        : 0.85256120\nF1 Score      : 0.92041353\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# SMOTE the whole dataset and save balanced CSV\nimport sys\nimport subprocess\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\n\n# try to import imblearn.SMOTE; install if missing\ntry:\n    from imblearn.over_sampling import SMOTE\nexcept Exception:\n    print(\"imblearn not found -> installing imbalanced-learn...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"imbalanced-learn\"])\n    from imblearn.over_sampling import SMOTE\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# ------------- CONFIG -------------\nINPUT_PATH = \"/kaggle/working/heart_attack_cleaned.csv\"   # change if needed\nTARGET = \"Heart_Attack\"\nOUTPUT_PATH = \"/kaggle/working/heart_attack_smoted.csv\"\nRANDOM_STATE = 42\n# ----------------------------------\n\n# 1) Load\ndf = pd.read_csv(INPUT_PATH)\nprint(\"Loaded:\", INPUT_PATH)\nprint(\"Initial shape:\", df.shape)\nif TARGET not in df.columns:\n    raise ValueError(f\"Target column '{TARGET}' not found in dataframe.\")\n\nprint(\"\\nOriginal target distribution (counts):\")\nprint(df[TARGET].value_counts())\n\n# 2) Separate X, y\nX = df.drop(TARGET, axis=1)\ny = df[TARGET].astype(int)\n\n# 3) Ensure all features numeric: label-encode object columns (so SMOTE can run)\nobj_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\nif len(obj_cols) > 0:\n    print(\"\\nLabel-encoding object columns for SMOTE:\", obj_cols)\n    le = LabelEncoder()\n    for col in obj_cols:\n        X[col] = le.fit_transform(X[col].astype(str))\n\n# 4) Convert any boolean to int (if present)\nbool_cols = X.select_dtypes(include=['bool']).columns.tolist()\nfor col in bool_cols:\n    X[col] = X[col].astype(int)\n\n# 5) Final dtype check\nnon_numeric = X.select_dtypes(exclude=[np.number]).columns.tolist()\nif non_numeric:\n    raise ValueError(\"Found non-numeric columns after encoding: \" + \", \".join(non_numeric))\n\n# 6) Apply SMOTE on full data (this creates synthetic minority samples)\nsmote = SMOTE(random_state=RANDOM_STATE, n_jobs=-1)\nX_res, y_res = smote.fit_resample(X, y)\n\nprint(\"\\nAfter SMOTE - distribution (counts):\")\nprint(Counter(y_res))\n\n# 7) Rebuild DataFrame and save\ndf_res = pd.DataFrame(X_res, columns=X.columns)\ndf_res[TARGET] = y_res\n\ndf_res.to_csv(OUTPUT_PATH, index=False)\nprint(\"\\n‚úÖ Saved balanced dataset to:\", OUTPUT_PATH)\nprint(\"Balanced shape:\", df_res.shape)\n\n# 8) Quick sanity checks\nprint(\"\\nPreview (first 3 rows):\")\nprint(df_res.head(3).to_string(index=False))\n\nprint(\"\\nTarget distribution (final):\")\nprint(df_res[TARGET].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T15:00:32.566216Z","iopub.execute_input":"2025-12-10T15:00:32.567162Z","iopub.status.idle":"2025-12-10T15:00:35.164807Z","shell.execute_reply.started":"2025-12-10T15:00:32.567125Z","shell.execute_reply":"2025-12-10T15:00:35.163634Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n  warnings.warn(\nException ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x79768c118e00>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n    self._make_controller_from_path(filepath)\n  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1187, in _make_controller_from_path\n    lib_controller = controller_class(\n                     ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 114, in __init__\n    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n    self._handle = _dlopen(self._name, mode)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: dlopen() error\n","output_type":"stream"},{"name":"stdout","text":"Loaded: /kaggle/working/heart_attack_cleaned.csv\nInitial shape: (50000, 29)\n\nOriginal target distribution (counts):\nHeart_Attack\n0    44119\n1     5881\nName: count, dtype: int64\n\nAfter SMOTE - distribution (counts):\nCounter({0: 44119, 1: 44119})\n\n‚úÖ Saved balanced dataset to: /kaggle/working/heart_attack_smoted.csv\nBalanced shape: (88238, 29)\n\nPreview (first 3 rows):\n     Age  Gender  Region  Blood_Pressure  Cholesterol      BMI  Heart_Rate  Exercise_Level  Smoking  Alcohol_Consumption  Diabetes  Family_History  Stress_Level  Angina  Heart_Disease_History  Diet  Sleep_Hours  Occupation  Income_Level  Physical_Activity  Education_Level  Marital_Status  Urban_Rural  Medication  Health_Awareness  Daily_Water_Intake  Mental_Health  Obesity  Heart_Attack\n0.791667       1       0        0.389408     0.515449 0.300926       0.400               0        0                    1         0               0      0.777778       0                      0     2         0.90           3             1                  1                1               1            0           0              1.00               0.325       0.444444        0             0\n0.583333       0       2        0.613707     0.422036 0.560185       0.550               2        0                    1         0               1      0.444444       1                      0     2         0.25           0             1                  2                0               1            1           0              0.00               1.000       0.333333        0             0\n0.291667       1       0        0.436137     0.548024 0.562500       0.275               2        0                    1         1               0      0.777778       0                      0     2         0.80           0             2                  0                1               1            1           0              0.75               0.350       0.777778        0             0\n\nTarget distribution (final):\nHeart_Attack\n0    44119\n1    44119\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install --upgrade \"scikit-learn==1.2.2\"\n!pip install --upgrade \"imbalanced-learn==0.10.1\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T15:00:14.166361Z","iopub.execute_input":"2025-12-10T15:00:14.166925Z","iopub.status.idle":"2025-12-10T15:00:25.886325Z","shell.execute_reply.started":"2025-12-10T15:00:14.166898Z","shell.execute_reply":"2025-12-10T15:00:25.885359Z"}},"outputs":[{"name":"stdout","text":"Collecting scikit-learn==1.2.2\n  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.6.1\n    Uninstalling scikit-learn-1.6.1:\n      Successfully uninstalled scikit-learn-1.6.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.2.2\nCollecting imbalanced-learn==0.10.1\n  Downloading imbalanced_learn-0.10.1-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.10.1) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.10.1) (1.15.3)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.10.1) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.10.1) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.10.1) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.10.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.10.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.10.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.10.1) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.10.1) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.10.1) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->imbalanced-learn==0.10.1) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->imbalanced-learn==0.10.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->imbalanced-learn==0.10.1) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->imbalanced-learn==0.10.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->imbalanced-learn==0.10.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->imbalanced-learn==0.10.1) (2024.2.0)\nDownloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: imbalanced-learn\n  Attempting uninstall: imbalanced-learn\n    Found existing installation: imbalanced-learn 0.13.0\n    Uninstalling imbalanced-learn-0.13.0:\n      Successfully uninstalled imbalanced-learn-0.13.0\nSuccessfully installed imbalanced-learn-0.10.1\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"dhoogla/cicddos2019\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:37:09.490999Z","iopub.execute_input":"2025-12-10T16:37:09.491287Z","iopub.status.idle":"2025-12-10T16:37:11.067716Z","shell.execute_reply.started":"2025-12-10T16:37:09.491259Z","shell.execute_reply":"2025-12-10T16:37:11.066901Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/cicddos2019\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/DNS-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:38:30.253603Z","iopub.execute_input":"2025-12-10T16:38:30.254041Z","iopub.status.idle":"2025-12-10T16:38:30.278985Z","shell.execute_reply.started":"2025-12-10T16:38:30.254020Z","shell.execute_reply":"2025-12-10T16:38:30.278051Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['DrDoS_DNS', 'Benign']\nCategories (2, object): ['Benign', 'DrDoS_DNS']\n\nLabel value counts:\nLabel\nDrDoS_DNS    3669\nBenign       3034\nName: count, dtype: int64\n(6703, 78)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/LDAP-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:40:16.023110Z","iopub.execute_input":"2025-12-10T16:40:16.023785Z","iopub.status.idle":"2025-12-10T16:40:16.060155Z","shell.execute_reply.started":"2025-12-10T16:40:16.023751Z","shell.execute_reply":"2025-12-10T16:40:16.059451Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['DrDoS_LDAP', 'Benign']\nCategories (2, object): ['Benign', 'DrDoS_LDAP']\n\nLabel value counts:\nLabel\nDrDoS_LDAP    1440\nBenign        1391\nName: count, dtype: int64\n(2831, 78)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/LDAP-training.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:41:28.123124Z","iopub.execute_input":"2025-12-10T16:41:28.123835Z","iopub.status.idle":"2025-12-10T16:41:28.162208Z","shell.execute_reply.started":"2025-12-10T16:41:28.123808Z","shell.execute_reply":"2025-12-10T16:41:28.161503Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['NetBIOS', 'LDAP', 'Benign']\nCategories (3, object): ['Benign', 'LDAP', 'NetBIOS']\n\nLabel value counts:\nLabel\nBenign     4585\nLDAP       1884\nNetBIOS     246\nName: count, dtype: int64\n(6715, 78)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/MSSQL-training.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:43:53.553797Z","iopub.execute_input":"2025-12-10T16:43:53.554159Z","iopub.status.idle":"2025-12-10T16:43:53.592765Z","shell.execute_reply.started":"2025-12-10T16:43:53.554136Z","shell.execute_reply":"2025-12-10T16:43:53.591885Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['MSSQL', 'LDAP', 'Benign']\nCategories (3, object): ['Benign', 'LDAP', 'MSSQL']\n\nLabel value counts:\nLabel\nMSSQL     8378\nBenign    2574\nLDAP        22\nName: count, dtype: int64\n(10974, 78)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/MSSQL-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:44:40.781704Z","iopub.execute_input":"2025-12-10T16:44:40.782429Z","iopub.status.idle":"2025-12-10T16:44:40.818178Z","shell.execute_reply.started":"2025-12-10T16:44:40.782398Z","shell.execute_reply":"2025-12-10T16:44:40.817447Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['DrDoS_MSSQL', 'Benign']\nCategories (2, object): ['Benign', 'DrDoS_MSSQL']\n\nLabel value counts:\nLabel\nDrDoS_MSSQL    6212\nBenign         1871\nName: count, dtype: int64\n(8083, 78)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/NTP-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:45:42.272777Z","iopub.execute_input":"2025-12-10T16:45:42.273619Z","iopub.status.idle":"2025-12-10T16:45:42.492197Z","shell.execute_reply.started":"2025-12-10T16:45:42.273588Z","shell.execute_reply":"2025-12-10T16:45:42.491358Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['DrDoS_NTP', 'Benign']\nCategories (2, object): ['Benign', 'DrDoS_NTP']\n\nLabel value counts:\nLabel\nDrDoS_NTP    121368\nBenign        13306\nName: count, dtype: int64\n(134674, 78)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/NetBIOS-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:46:36.337965Z","iopub.execute_input":"2025-12-10T16:46:36.338659Z","iopub.status.idle":"2025-12-10T16:46:36.372000Z","shell.execute_reply.started":"2025-12-10T16:46:36.338631Z","shell.execute_reply":"2025-12-10T16:46:36.371131Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['DrDoS_NetBIOS', 'Benign']\nCategories (2, object): ['Benign', 'DrDoS_NetBIOS']\n\nLabel value counts:\nLabel\nBenign           1627\nDrDoS_NetBIOS     598\nName: count, dtype: int64\n(2225, 78)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/NetBIOS-training.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:47:59.683498Z","iopub.execute_input":"2025-12-10T16:47:59.683829Z","iopub.status.idle":"2025-12-10T16:47:59.714555Z","shell.execute_reply.started":"2025-12-10T16:47:59.683809Z","shell.execute_reply":"2025-12-10T16:47:59.713842Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['NetBIOS', 'Benign']\nCategories (2, object): ['Benign', 'NetBIOS']\n\nLabel value counts:\nLabel\nBenign     1233\nNetBIOS     398\nName: count, dtype: int64\n(1631, 78)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/Portmap-training.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:48:58.703663Z","iopub.execute_input":"2025-12-10T16:48:58.704381Z","iopub.status.idle":"2025-12-10T16:48:58.741717Z","shell.execute_reply.started":"2025-12-10T16:48:58.704352Z","shell.execute_reply":"2025-12-10T16:48:58.740737Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['Portmap', 'Benign']\nCategories (2, object): ['Benign', 'Portmap']\n\nLabel value counts:\nLabel\nBenign     4420\nPortmap     685\nName: count, dtype: int64\n(5105, 78)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/SNMP-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:50:02.593476Z","iopub.execute_input":"2025-12-10T16:50:02.593769Z","iopub.status.idle":"2025-12-10T16:50:02.625018Z","shell.execute_reply.started":"2025-12-10T16:50:02.593748Z","shell.execute_reply":"2025-12-10T16:50:02.624298Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['DrDoS_SNMP', 'Benign']\nCategories (2, object): ['Benign', 'DrDoS_SNMP']\n\nLabel value counts:\nLabel\nDrDoS_SNMP    2717\nBenign        1301\nName: count, dtype: int64\n(4018, 78)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/Syn-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:51:09.692771Z","iopub.execute_input":"2025-12-10T16:51:09.693127Z","iopub.status.idle":"2025-12-10T16:51:09.725112Z","shell.execute_reply.started":"2025-12-10T16:51:09.693104Z","shell.execute_reply":"2025-12-10T16:51:09.724310Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['Syn', 'Benign']\nCategories (2, object): ['Benign', 'Syn']\n\nLabel value counts:\nLabel\nSyn       533\nBenign    374\nName: count, dtype: int64\n(907, 78)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/Syn-training.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:51:24.403170Z","iopub.execute_input":"2025-12-10T16:51:24.403897Z","iopub.status.idle":"2025-12-10T16:51:24.533934Z","shell.execute_reply.started":"2025-12-10T16:51:24.403872Z","shell.execute_reply":"2025-12-10T16:51:24.533045Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['Syn', 'Benign']\nCategories (2, object): ['Benign', 'Syn']\n\nLabel value counts:\nLabel\nSyn       43302\nBenign    27034\nName: count, dtype: int64\n(70336, 78)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/TFTP-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:52:57.733503Z","iopub.execute_input":"2025-12-10T16:52:57.733847Z","iopub.status.idle":"2025-12-10T16:52:57.940623Z","shell.execute_reply.started":"2025-12-10T16:52:57.733826Z","shell.execute_reply":"2025-12-10T16:52:57.939739Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['TFTP', 'Benign']\nCategories (2, object): ['Benign', 'TFTP']\n\nLabel value counts:\nLabel\nTFTP      98917\nBenign    22916\nName: count, dtype: int64\n(121833, 78)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/UDP-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:54:04.333345Z","iopub.execute_input":"2025-12-10T16:54:04.333668Z","iopub.status.idle":"2025-12-10T16:54:04.373933Z","shell.execute_reply.started":"2025-12-10T16:54:04.333646Z","shell.execute_reply":"2025-12-10T16:54:04.373264Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['DrDoS_UDP', 'Benign']\nCategories (2, object): ['Benign', 'DrDoS_UDP']\n\nLabel value counts:\nLabel\nDrDoS_UDP    10420\nBenign        2042\nName: count, dtype: int64\n(12462, 78)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/UDP-training.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:55:07.533615Z","iopub.execute_input":"2025-12-10T16:55:07.534338Z","iopub.status.idle":"2025-12-10T16:55:07.577647Z","shell.execute_reply.started":"2025-12-10T16:55:07.534312Z","shell.execute_reply":"2025-12-10T16:55:07.576892Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['UDP', 'MSSQL', 'Benign']\nCategories (3, object): ['Benign', 'MSSQL', 'UDP']\n\nLabel value counts:\nLabel\nUDP       14792\nBenign     2833\nMSSQL       145\nName: count, dtype: int64\n(17770, 78)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/UDPLag-training.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:56:23.033536Z","iopub.execute_input":"2025-12-10T16:56:23.033879Z","iopub.status.idle":"2025-12-10T16:56:23.135316Z","shell.execute_reply.started":"2025-12-10T16:56:23.033859Z","shell.execute_reply":"2025-12-10T16:56:23.134423Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['UDP', 'Syn', 'UDPLag', 'Benign']\nCategories (4, object): ['Benign', 'Syn', 'UDP', 'UDPLag']\n\nLabel value counts:\nLabel\nSyn       5538\nBenign    3748\nUDP       3298\nUDPLag      55\nName: count, dtype: int64\n(12639, 78)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\n\n# Load the parquet file\ndf = pd.read_parquet(\"/kaggle/input/cicddos2019/UDPLag-testing.parquet\")\n\n# Show columns\nprint(\"Columns in the dataset:\\n\")\nprint(df.columns.tolist())\n\n# Check unique values in Label\nprint(\"\\nUnique values in 'Label' column:\")\nprint(df[\"Label\"].unique())\n\n# Count of each Label\nprint(\"\\nLabel value counts:\")\nprint(df[\"Label\"].value_counts())\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:57:07.683482Z","iopub.execute_input":"2025-12-10T16:57:07.684339Z","iopub.status.idle":"2025-12-10T16:57:07.782382Z","shell.execute_reply.started":"2025-12-10T16:57:07.684311Z","shell.execute_reply":"2025-12-10T16:57:07.781488Z"}},"outputs":[{"name":"stdout","text":"Columns in the dataset:\n\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in 'Label' column:\n['UDP-lag', 'WebDDoS', 'Benign']\nCategories (3, object): ['Benign', 'UDP-lag', 'WebDDoS']\n\nLabel value counts:\nLabel\nUDP-lag    8872\nBenign     3542\nWebDDoS      51\nName: count, dtype: int64\n(12465, 78)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Combine selected label slices from multiple CIC-DDoS-2019 parquet files\n# and save a single CSV for downstream experiments.\n#\n# Edit `SELECTIONS` if you want to change counts.\n\nimport pandas as pd\nimport os\nfrom collections import Counter\n\n# ------------------------------\n# CONFIG: file -> {label: count, ...}\n# ------------------------------\nSELECTIONS = {\n    \"/kaggle/input/cicddos2019/DNS-testing.parquet\": {\n        \"Benign\": 3034,\n        \"DrDoS_DNS\": 3661\n    },\n    \"/kaggle/input/cicddos2019/LDAP-testing.parquet\": {\n        \"Benign\": 1391,\n        \"DrDoS_LDAP\": 1440\n    },\n    \"/kaggle/input/cicddos2019/LDAP-training.parquet\": {\n        \"Benign\": 4585,\n        \"LDAP\": 1884,\n        \"NetBIOS\": 246\n    },\n    \"/kaggle/input/cicddos2019/MSSQL-testing.parquet\": {\n        \"Benign\": 1871,\n        \"DrDoS_MSSQL\": 3861\n    },\n    \"/kaggle/input/cicddos2019/MSSQL-training.parquet\": {\n        \"Benign\": 2574,\n        \"MSSQL\": 3761,\n        \"LDAP\": 22\n    },\n    \"/kaggle/input/cicddos2019/NTP-testing.parquet\": {\n        \"Benign\": 13306,\n        \"DrDoS_NTP\": 3879\n    },\n    \"/kaggle/input/cicddos2019/NetBIOS-testing.parquet\": {\n        \"Benign\": 1627,\n        \"DrDoS_NetBIOS\": 598\n    },\n    \"/kaggle/input/cicddos2019/NetBIOS-training.parquet\": {\n        \"Benign\": 1233,\n        \"NetBIOS\": 398\n    },\n    \"/kaggle/input/cicddos2019/Portmap-training.parquet\": {\n        \"Benign\": 4420,\n        \"Portmap\": 685\n    },\n    \"/kaggle/input/cicddos2019/SNMP-testing.parquet\": {\n        \"Benign\": 1301,\n        \"DrDoS_SNMP\": 2717\n    },\n    \"/kaggle/input/cicddos2019/Syn-testing.parquet\": {\n        \"Benign\": 374,\n        \"Syn\": 533\n    },\n    \"/kaggle/input/cicddos2019/Syn-training.parquet\": {\n        \"Benign\": 14284,\n        \"Syn\": 3661\n    },\n    \"/kaggle/input/cicddos2019/TFTP-testing.parquet\": {\n        \"TFTP\": 3861\n    },\n    \"/kaggle/input/cicddos2019/UDP-testing.parquet\": {\n        \"DrDoS_UDP\": 3861\n    },\n    \"/kaggle/input/cicddos2019/UDP-training.parquet\": {\n        \"UDP\": 3861,\n        \"MSSQL\": 145\n    },\n    \"/kaggle/input/cicddos2019/UDPLag-testing.parquet\": {\n        \"UDP-lag\": 3861,\n        \"WebDDoS\": 51\n    },\n    \"/kaggle/input/cicddos2019/UDPLag-training.parquet\": {\n        \"Syn\": 3661,\n        \"UDP\": 3298,\n        \"UDPLag\": 55\n    }\n}\n\nOUTPUT_PATH = \"/kaggle/working/cicddos2019_selected_combined.csv\"\nrandom_state = 42\n\n# ------------------------------\n# Processing\n# ------------------------------\nselected_parts = []\nsummary = []\n\nfor path, label_counts in SELECTIONS.items():\n    if not os.path.exists(path):\n        print(f\"WARNING: file not found -> {path}  (skipping)\")\n        continue\n\n    print(f\"\\nLoading: {path}\")\n    df = pd.read_parquet(path)\n    # Ensure 'Label' column exists\n    if \"Label\" not in df.columns:\n        print(f\"  ERROR: 'Label' column not found in {path} - skipping this file.\")\n        continue\n\n    for label, req_count in label_counts.items():\n        df_label = df[df[\"Label\"] == label]\n        available = len(df_label)\n        take = min(req_count, available)\n        if take == 0:\n            print(f\"  - Label '{label}' not found in file (requested {req_count}, available {available})\")\n            continue\n\n        # sampling: if available >= take, sample without replacement, else take all\n        if available >= take:\n            sampled = df_label.sample(n=take, random_state=random_state)\n        else:\n            sampled = df_label.copy()  # take all\n            print(f\"  - NOTE: requested {req_count} rows but only {available} available for label '{label}' in {os.path.basename(path)}; taking {available}.\")\n\n        selected_parts.append(sampled)\n        summary.append((os.path.basename(path), label, req_count, available, len(sampled)))\n        print(f\"  -> Selected {len(sampled):5d} rows for label '{label}' (requested {req_count}, available {available})\")\n\n# Combine parts\nif len(selected_parts) == 0:\n    raise RuntimeError(\"No rows were selected from any file. Check paths / labels in SELECTIONS.\")\n\ncombined = pd.concat(selected_parts, ignore_index=True).sample(frac=1, random_state=random_state).reset_index(drop=True)\n\n# Save\ncombined.to_csv(OUTPUT_PATH, index=False)\nprint(\"\\n\\n‚úÖ Combined CSV saved to:\", OUTPUT_PATH)\nprint(\"Combined shape:\", combined.shape)\n\n# Print summary table\nprint(\"\\nSelection summary (file, label, requested, available, taken):\")\nfor row in summary:\n    print(row)\n\n# Print final Label distribution\nprint(\"\\nFinal 'Label' value counts in combined dataset:\")\nprint(combined[\"Label\"].value_counts())\n\n# Optional: show columns and sample head\nprint(\"\\nColumns (count={}):\".format(len(combined.columns)))\nprint(combined.columns.tolist())\nprint(\"\\nSample rows:\")\nprint(combined.head(3).to_string(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:44:17.688097Z","iopub.execute_input":"2025-12-10T17:44:17.688978Z","iopub.status.idle":"2025-12-10T17:44:22.684979Z","shell.execute_reply.started":"2025-12-10T17:44:17.688940Z","shell.execute_reply":"2025-12-10T17:44:22.684222Z"}},"outputs":[{"name":"stdout","text":"\nLoading: /kaggle/input/cicddos2019/DNS-testing.parquet\n  -> Selected  3034 rows for label 'Benign' (requested 3034, available 3034)\n  -> Selected  3661 rows for label 'DrDoS_DNS' (requested 3661, available 3669)\n\nLoading: /kaggle/input/cicddos2019/LDAP-testing.parquet\n  -> Selected  1391 rows for label 'Benign' (requested 1391, available 1391)\n  -> Selected  1440 rows for label 'DrDoS_LDAP' (requested 1440, available 1440)\n\nLoading: /kaggle/input/cicddos2019/LDAP-training.parquet\n  -> Selected  4585 rows for label 'Benign' (requested 4585, available 4585)\n  -> Selected  1884 rows for label 'LDAP' (requested 1884, available 1884)\n  -> Selected   246 rows for label 'NetBIOS' (requested 246, available 246)\n\nLoading: /kaggle/input/cicddos2019/MSSQL-testing.parquet\n  -> Selected  1871 rows for label 'Benign' (requested 1871, available 1871)\n  -> Selected  3861 rows for label 'DrDoS_MSSQL' (requested 3861, available 6212)\n\nLoading: /kaggle/input/cicddos2019/MSSQL-training.parquet\n  -> Selected  2574 rows for label 'Benign' (requested 2574, available 2574)\n  -> Selected  3761 rows for label 'MSSQL' (requested 3761, available 8378)\n  -> Selected    22 rows for label 'LDAP' (requested 22, available 22)\n\nLoading: /kaggle/input/cicddos2019/NTP-testing.parquet\n  -> Selected 13306 rows for label 'Benign' (requested 13306, available 13306)\n  -> Selected  3879 rows for label 'DrDoS_NTP' (requested 3879, available 121368)\n\nLoading: /kaggle/input/cicddos2019/NetBIOS-testing.parquet\n  -> Selected  1627 rows for label 'Benign' (requested 1627, available 1627)\n  -> Selected   598 rows for label 'DrDoS_NetBIOS' (requested 598, available 598)\n\nLoading: /kaggle/input/cicddos2019/NetBIOS-training.parquet\n  -> Selected  1233 rows for label 'Benign' (requested 1233, available 1233)\n  -> Selected   398 rows for label 'NetBIOS' (requested 398, available 398)\n\nLoading: /kaggle/input/cicddos2019/Portmap-training.parquet\n  -> Selected  4420 rows for label 'Benign' (requested 4420, available 4420)\n  -> Selected   685 rows for label 'Portmap' (requested 685, available 685)\n\nLoading: /kaggle/input/cicddos2019/SNMP-testing.parquet\n  -> Selected  1301 rows for label 'Benign' (requested 1301, available 1301)\n  -> Selected  2717 rows for label 'DrDoS_SNMP' (requested 2717, available 2717)\n\nLoading: /kaggle/input/cicddos2019/Syn-testing.parquet\n  -> Selected   374 rows for label 'Benign' (requested 374, available 374)\n  -> Selected   533 rows for label 'Syn' (requested 533, available 533)\n\nLoading: /kaggle/input/cicddos2019/Syn-training.parquet\n  -> Selected 14284 rows for label 'Benign' (requested 14284, available 27034)\n  -> Selected  3661 rows for label 'Syn' (requested 3661, available 43302)\n\nLoading: /kaggle/input/cicddos2019/TFTP-testing.parquet\n  -> Selected  3861 rows for label 'TFTP' (requested 3861, available 98917)\n\nLoading: /kaggle/input/cicddos2019/UDP-testing.parquet\n  -> Selected  3861 rows for label 'DrDoS_UDP' (requested 3861, available 10420)\n\nLoading: /kaggle/input/cicddos2019/UDP-training.parquet\n  -> Selected  3861 rows for label 'UDP' (requested 3861, available 14792)\n  -> Selected   145 rows for label 'MSSQL' (requested 145, available 145)\n\nLoading: /kaggle/input/cicddos2019/UDPLag-testing.parquet\n  -> Selected  3861 rows for label 'UDP-lag' (requested 3861, available 8872)\n  -> Selected    51 rows for label 'WebDDoS' (requested 51, available 51)\n\nLoading: /kaggle/input/cicddos2019/UDPLag-training.parquet\n  -> Selected  3661 rows for label 'Syn' (requested 3661, available 5538)\n  -> Selected  3298 rows for label 'UDP' (requested 3298, available 3298)\n  -> Selected    55 rows for label 'UDPLag' (requested 55, available 55)\n\n\n‚úÖ Combined CSV saved to: /kaggle/working/cicddos2019_selected_combined.csv\nCombined shape: (100000, 78)\n\nSelection summary (file, label, requested, available, taken):\n('DNS-testing.parquet', 'Benign', 3034, 3034, 3034)\n('DNS-testing.parquet', 'DrDoS_DNS', 3661, 3669, 3661)\n('LDAP-testing.parquet', 'Benign', 1391, 1391, 1391)\n('LDAP-testing.parquet', 'DrDoS_LDAP', 1440, 1440, 1440)\n('LDAP-training.parquet', 'Benign', 4585, 4585, 4585)\n('LDAP-training.parquet', 'LDAP', 1884, 1884, 1884)\n('LDAP-training.parquet', 'NetBIOS', 246, 246, 246)\n('MSSQL-testing.parquet', 'Benign', 1871, 1871, 1871)\n('MSSQL-testing.parquet', 'DrDoS_MSSQL', 3861, 6212, 3861)\n('MSSQL-training.parquet', 'Benign', 2574, 2574, 2574)\n('MSSQL-training.parquet', 'MSSQL', 3761, 8378, 3761)\n('MSSQL-training.parquet', 'LDAP', 22, 22, 22)\n('NTP-testing.parquet', 'Benign', 13306, 13306, 13306)\n('NTP-testing.parquet', 'DrDoS_NTP', 3879, 121368, 3879)\n('NetBIOS-testing.parquet', 'Benign', 1627, 1627, 1627)\n('NetBIOS-testing.parquet', 'DrDoS_NetBIOS', 598, 598, 598)\n('NetBIOS-training.parquet', 'Benign', 1233, 1233, 1233)\n('NetBIOS-training.parquet', 'NetBIOS', 398, 398, 398)\n('Portmap-training.parquet', 'Benign', 4420, 4420, 4420)\n('Portmap-training.parquet', 'Portmap', 685, 685, 685)\n('SNMP-testing.parquet', 'Benign', 1301, 1301, 1301)\n('SNMP-testing.parquet', 'DrDoS_SNMP', 2717, 2717, 2717)\n('Syn-testing.parquet', 'Benign', 374, 374, 374)\n('Syn-testing.parquet', 'Syn', 533, 533, 533)\n('Syn-training.parquet', 'Benign', 14284, 27034, 14284)\n('Syn-training.parquet', 'Syn', 3661, 43302, 3661)\n('TFTP-testing.parquet', 'TFTP', 3861, 98917, 3861)\n('UDP-testing.parquet', 'DrDoS_UDP', 3861, 10420, 3861)\n('UDP-training.parquet', 'UDP', 3861, 14792, 3861)\n('UDP-training.parquet', 'MSSQL', 145, 145, 145)\n('UDPLag-testing.parquet', 'UDP-lag', 3861, 8872, 3861)\n('UDPLag-testing.parquet', 'WebDDoS', 51, 51, 51)\n('UDPLag-training.parquet', 'Syn', 3661, 5538, 3661)\n('UDPLag-training.parquet', 'UDP', 3298, 3298, 3298)\n('UDPLag-training.parquet', 'UDPLag', 55, 55, 55)\n\nFinal 'Label' value counts in combined dataset:\nLabel\nBenign           50000\nSyn               7855\nUDP               7159\nMSSQL             3906\nDrDoS_NTP         3879\nTFTP              3861\nUDP-lag           3861\nDrDoS_UDP         3861\nDrDoS_MSSQL       3861\nDrDoS_DNS         3661\nDrDoS_SNMP        2717\nLDAP              1906\nDrDoS_LDAP        1440\nPortmap            685\nNetBIOS            644\nDrDoS_NetBIOS      598\nUDPLag              55\nWebDDoS             51\nName: count, dtype: int64\n\nColumns (count=78):\n['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nSample rows:\n Protocol  Flow Duration  Total Fwd Packets  Total Backward Packets  Fwd Packets Length Total  Bwd Packets Length Total  Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  Bwd Packet Length Max  Bwd Packet Length Min  Bwd Packet Length Mean  Bwd Packet Length Std  Flow Bytes/s  Flow Packets/s  Flow IAT Mean  Flow IAT Std  Flow IAT Max  Flow IAT Min  Fwd IAT Total  Fwd IAT Mean  Fwd IAT Std  Fwd IAT Max  Fwd IAT Min  Bwd IAT Total  Bwd IAT Mean  Bwd IAT Std  Bwd IAT Max  Bwd IAT Min  Fwd PSH Flags  Bwd PSH Flags  Fwd URG Flags  Bwd URG Flags  Fwd Header Length  Bwd Header Length  Fwd Packets/s  Bwd Packets/s  Packet Length Min  Packet Length Max  Packet Length Mean  Packet Length Std  Packet Length Variance  FIN Flag Count  SYN Flag Count  RST Flag Count  PSH Flag Count  ACK Flag Count  URG Flag Count  CWE Flag Count  ECE Flag Count  Down/Up Ratio  Avg Packet Size  Avg Fwd Segment Size  Avg Bwd Segment Size  Fwd Avg Bytes/Bulk  Fwd Avg Packets/Bulk  Fwd Avg Bulk Rate  Bwd Avg Bytes/Bulk  Bwd Avg Packets/Bulk  Bwd Avg Bulk Rate  Subflow Fwd Packets  Subflow Fwd Bytes  Subflow Bwd Packets  Subflow Bwd Bytes  Init Fwd Win Bytes  Init Bwd Win Bytes  Fwd Act Data Packets  Fwd Seg Size Min  Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min       Label\n        6        3627045                  6                       0                      36.0                       0.0                    6.0                    6.0                     6.0                    0.0                    0.0                    0.0                     0.0                    0.0  9.925435e+00        1.654239       725409.0   1273070.125     2939636.0           1.0      3627045.0      725409.0  1273070.125    2939636.0          1.0            0.0           0.0          0.0          0.0          0.0              0              0              0              0                120                  0       1.654239            0.0                6.0                6.0                 6.0                0.0                     0.0               0               0               0               0               1               0               0               0            0.0              7.0                   6.0                   0.0                   0                     0                  0                   0                     0                  0                    6                 36                    0                  0                5840                  -1                     5                20          0.0         0.0         0.0         0.0        0.0       0.0       0.0       0.0         Syn\n       17        3000111                  4                       0                    2064.0                       0.0                  516.0                  516.0                   516.0                    0.0                    0.0                    0.0                     0.0                    0.0  6.879745e+02        1.333284      1000037.0   1732078.500     3000069.0           1.0      3000111.0     1000037.0  1732078.500    3000069.0          1.0            0.0           0.0          0.0          0.0          0.0              0              0              0              0                 38                  0       1.333284            0.0              516.0              516.0               516.0                0.0                     0.0               0               0               0               0               0               0               0               0            0.0            645.0                 516.0                   0.0                   0                     0                  0                   0                     0                  0                    4               2064                    0                  0                  -1                  -1                     3                -1          0.0         0.0         0.0         0.0        0.0       0.0       0.0       0.0        TFTP\n       17              2                  2                       0                    1096.0                       0.0                  548.0                  548.0                   548.0                    0.0                    0.0                    0.0                     0.0                    0.0  5.480000e+08  1000000.000000            2.0         0.000           2.0           2.0            2.0           2.0        0.000          2.0          2.0            0.0           0.0          0.0          0.0          0.0              0              0              0              0                 40                  0 1000000.000000            0.0              548.0              548.0               548.0                0.0                     0.0               0               0               0               0               0               0               0               0            0.0            822.0                 548.0                   0.0                   0                     0                  0                   0                     0                  0                    2               1096                    0                  0                  -1                  -1                     1                20          0.0         0.0         0.0         0.0        0.0       0.0       0.0       0.0 DrDoS_MSSQL\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"d=pd.read_csv(\"/kaggle/working/cicddos2019_selected_combined.csv\")\nd.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:45:06.647841Z","iopub.execute_input":"2025-12-10T17:45:06.648188Z","iopub.status.idle":"2025-12-10T17:45:07.495280Z","shell.execute_reply.started":"2025-12-10T17:45:06.648164Z","shell.execute_reply":"2025-12-10T17:45:07.494383Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(100000, 78)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"d.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:45:15.867101Z","iopub.execute_input":"2025-12-10T17:45:15.867440Z","iopub.status.idle":"2025-12-10T17:45:15.875051Z","shell.execute_reply.started":"2025-12-10T17:45:15.867418Z","shell.execute_reply":"2025-12-10T17:45:15.874348Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Index(['Protocol', 'Flow Duration', 'Total Fwd Packets',\n       'Total Backward Packets', 'Fwd Packets Length Total',\n       'Bwd Packets Length Total', 'Fwd Packet Length Max',\n       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n       'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n       'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n       'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n       'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate',\n       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n       'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes',\n       'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n       'Idle Min', 'Label'],\n      dtype='object')"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"print(\"Columns:\\n\", d.columns.tolist())\n\nprint(\"\\nUnique values in Label:\")\nprint(d[\"Label\"].unique())\n\nprint(\"\\nLabel value counts:\")\nprint(d[\"Label\"].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:45:57.247706Z","iopub.execute_input":"2025-12-10T17:45:57.248008Z","iopub.status.idle":"2025-12-10T17:45:57.268776Z","shell.execute_reply.started":"2025-12-10T17:45:57.247984Z","shell.execute_reply":"2025-12-10T17:45:57.267720Z"}},"outputs":[{"name":"stdout","text":"Columns:\n ['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in Label:\n['Syn' 'TFTP' 'DrDoS_MSSQL' 'DrDoS_UDP' 'Benign' 'MSSQL' 'DrDoS_NTP' 'UDP'\n 'LDAP' 'UDP-lag' 'NetBIOS' 'DrDoS_DNS' 'Portmap' 'DrDoS_SNMP'\n 'DrDoS_LDAP' 'DrDoS_NetBIOS' 'UDPLag' 'WebDDoS']\n\nLabel value counts:\nLabel\nBenign           50000\nSyn               7855\nUDP               7159\nMSSQL             3906\nDrDoS_NTP         3879\nTFTP              3861\nUDP-lag           3861\nDrDoS_UDP         3861\nDrDoS_MSSQL       3861\nDrDoS_DNS         3661\nDrDoS_SNMP        2717\nLDAP              1906\nDrDoS_LDAP        1440\nPortmap            685\nNetBIOS            644\nDrDoS_NetBIOS      598\nUDPLag              55\nWebDDoS             51\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\n\n# -------------------------------\n# 1. Load dataset\n# -------------------------------\ndf = pd.read_csv(\"/kaggle/working/cicddos2019_selected_combined.csv\")  # your combined file\nprint(\"Initial shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())\n\n# -------------------------------\n# 2. Convert Label column ‚Üí binary (Benign = 0, Others = 1)\n# -------------------------------\ndf[\"Label\"] = df[\"Label\"].apply(lambda x: 0 if x == \"Benign\" else 1).astype(int)\n\nprint(\"\\nUnique values in Label:\", df[\"Label\"].unique())\nprint(\"Label counts:\\n\", df[\"Label\"].value_counts())\n\n# -------------------------------\n# 3. Drop useless columns (if any)\n# -------------------------------\nif \"ID\" in df.columns:\n    df = df.drop(\"ID\", axis=1)\n\n# -------------------------------\n# 4. Detect numeric + categorical columns\n# -------------------------------\nnum_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\ncat_cols = df.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n\n# Remove target from numeric/categorical lists\nif \"Label\" in num_cols:\n    num_cols.remove(\"Label\")\nif \"Label\" in cat_cols:\n    cat_cols.remove(\"Label\")\n\nprint(\"\\nNumeric columns:\", num_cols)\nprint(\"Categorical columns:\", cat_cols)\n\n# -------------------------------\n# 5. Handle missing values\n# -------------------------------\n# Numeric ‚Üí fill with median\nif len(num_cols) > 0:\n    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Categorical ‚Üí fill with mode\nfor col in cat_cols:\n    if df[col].isnull().any():\n        df[col] = df[col].fillna(df[col].mode()[0])\n\n# -------------------------------\n# 6. Label-encode categorical columns\n# -------------------------------\nle = LabelEncoder()\nfor col in cat_cols:\n    df[col] = le.fit_transform(df[col].astype(str))\n\n# -------------------------------\n# 7. Scale numeric columns\n# -------------------------------\nscaler = MinMaxScaler()\nif len(num_cols) > 0:\n    df[num_cols] = scaler.fit_transform(df[num_cols])\n\n# -------------------------------\n# 8. Save cleaned dataset\n# -------------------------------\noutput_path = \"/kaggle/working/cicddos2019_cleaned_final.csv\"\ndf.to_csv(output_path, index=False)\n\nprint(\"\\n‚úÖ Preprocessing Complete!\")\nprint(\"üìÅ Saved as:\", output_path)\nprint(\"Final Shape:\", df.shape)\n\nprint(\"\\nFinal Label distribution:\")\nprint(df[\"Label\"].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:49:05.467274Z","iopub.execute_input":"2025-12-10T17:49:05.467578Z","iopub.status.idle":"2025-12-10T17:49:16.499619Z","shell.execute_reply.started":"2025-12-10T17:49:05.467558Z","shell.execute_reply":"2025-12-10T17:49:16.498818Z"}},"outputs":[{"name":"stdout","text":"Initial shape: (100000, 78)\nColumns: ['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n\nUnique values in Label: [1 0]\nLabel counts:\n Label\n1    50000\n0    50000\nName: count, dtype: int64\n\nNumeric columns: ['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\nCategorical columns: []\n\n‚úÖ Preprocessing Complete!\nüìÅ Saved as: /kaggle/working/cicddos2019_cleaned_final.csv\nFinal Shape: (100000, 78)\n\nFinal Label distribution:\nLabel\n1    50000\n0    50000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/working/cicddos2019_cleaned_final.csv\")\n\nX = df.drop(\"Label\",axis=1)\ny = df[\"Label\"].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:51:11.446651Z","iopub.execute_input":"2025-12-10T17:51:11.447218Z","iopub.status.idle":"2025-12-10T17:51:12.722683Z","shell.execute_reply.started":"2025-12-10T17:51:11.447192Z","shell.execute_reply":"2025-12-10T17:51:12.721771Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport pandas as pd\n\n# Load dataset\n\nprint(\"Original dimension:\", X.shape[1])\n\n# -----------------------------\n# Train-test split\n# -----------------------------\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.20, stratify=y, random_state=42\n)\n\n# -----------------------------\n# XGBoost Model\n# -----------------------------\nmodel = XGBClassifier(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    objective=\"binary:logistic\",\n    eval_metric=\"logloss\",\n    random_state=42,\n    n_jobs=-1\n)\n\nmodel.fit(X_train, y_train)\n\n# -----------------------------\n# Predictions\n# -----------------------------\ny_pred = model.predict(X_test)\n\ntest_acc = accuracy_score(y_test, y_pred)\ntest_prec = precision_score(y_test, y_pred, zero_division=0)\ntest_rec = recall_score(y_test, y_pred, zero_division=0)\ntest_f1 = f1_score(y_test, y_pred, zero_division=0)\n\n# -----------------------------\n# Final Results\n# -----------------------------\nprint(\"\\n===== XGBoost Results =====\")\nprint(f\"Test Accuracy : {test_acc:.8f}\")\nprint(f\"Precision     : {test_prec:.8f}\")\nprint(f\"Recall        : {test_rec:.8f}\")\nprint(f\"F1 Score      : {test_f1:.8f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:51:16.246833Z","iopub.execute_input":"2025-12-10T17:51:16.247218Z","iopub.status.idle":"2025-12-10T17:51:22.387751Z","shell.execute_reply.started":"2025-12-10T17:51:16.247187Z","shell.execute_reply":"2025-12-10T17:51:22.386887Z"}},"outputs":[{"name":"stdout","text":"Original dimension: 77\n\n===== XGBoost Results =====\nTest Accuracy : 0.99885000\nPrecision     : 0.99939934\nRecall        : 0.99830000\nF1 Score      : 0.99884937\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(\"hi\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T18:00:42.926745Z","iopub.execute_input":"2025-12-10T18:00:42.927475Z","iopub.status.idle":"2025-12-10T18:00:42.932061Z","shell.execute_reply.started":"2025-12-10T18:00:42.927444Z","shell.execute_reply":"2025-12-10T18:00:42.931402Z"}},"outputs":[{"name":"stdout","text":"hi\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"pca 2019cicid","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\nimport pandas as pd\nfrom xgboost import XGBClassifier   # üî• NEW\n\ndf = pd.read_csv(\"/kaggle/working/cicddos2019_cleaned_final.csv\")\n\nX = df.drop(\"Label\",axis=1)\ny = df[\"Label\"].astype(int)\n\n# 1) Scale\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# 2) PCA to retain 95% variance\npca = PCA(n_components=0.95)  \nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Original dimension:\", X.shape[1])\nprint(\"PCA dimension:\", X_pca.shape[1])\n\n# 3) Train/Test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_pca, y, test_size=0.20, stratify=y, random_state=42\n)\n\n# ---------------------------------------------------\n# 4) ‚ùó Replace CatBoost with XGBoost\n# ---------------------------------------------------\nmodel = XGBClassifier(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    objective=\"binary:logistic\",\n    eval_metric=\"logloss\",\n    tree_method=\"hist\"        # Fast training\n)\n\n# Fit\nmodel.fit(X_train, y_train)\n\n# Test prediction\ny_pred = model.predict(X_test)\n\n# Metrics\ntest_acc = accuracy_score(y_test, y_pred)\ntest_prec = precision_score(y_test, y_pred, zero_division=0)\ntest_rec = recall_score(y_test, y_pred, zero_division=0)\ntest_f1 = f1_score(y_test, y_pred, zero_division=0)\n\nprint(\"\\n=== PCA + XGBOOST MODEL RESULTS ===\")\nprint(\"Test Accuracy :\", test_acc)\nprint(\"Precision     :\", test_prec)\nprint(\"Recall        :\", test_rec)\nprint(\"F1 Score      :\", test_f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T18:19:14.684963Z","iopub.execute_input":"2025-12-10T18:19:14.685319Z","iopub.status.idle":"2025-12-10T18:19:20.678922Z","shell.execute_reply.started":"2025-12-10T18:19:14.685297Z","shell.execute_reply":"2025-12-10T18:19:20.678152Z"}},"outputs":[{"name":"stdout","text":"Original dimension: 77\nPCA dimension: 24\n\n=== PCA + XGBOOST MODEL RESULTS ===\nTest Accuracy : 0.9985\nPrecision     : 0.9987992795677406\nRecall        : 0.9982\nF1 Score      : 0.9984995498649595\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"chi square","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nfrom xgboost import XGBClassifier   # ‚Üê changed\n\n# -------------------------\n# 1. Prepare data\n# -------------------------\n\nprint(\"Original dimension:\", X.shape[1])\n\n# Train-test split (same style as your hybrid pipeline)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.20,\n    stratify=y,\n    random_state=42\n)\n\n# -------------------------\n# 2. Scale to non-negative for chi-square\n# -------------------------\nscaler = MinMaxScaler()   # maps features to [0, 1]\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# -------------------------\n# 3. Try different numbers of selected features\n# -------------------------\nk_values = [5, 10, 15, 20, 16,13]\n\nresults_chi2 = {}\n\nfor k in k_values:\n    print(\"\\n\" + \"=\"*60)\n    print(f\"CHI-SQUARE + XGBoost with top-{k} features\")\n    print(\"=\"*60)\n\n    # 3.1 Chi-Square feature selection\n    selector = SelectKBest(score_func=chi2, k=k)\n    X_train_k = selector.fit_transform(X_train_scaled, y_train)\n    X_test_k = selector.transform(X_test_scaled)\n\n    # Get selected feature names (from original X)\n    selected_mask = selector.get_support()\n    selected_features = X.columns[selected_mask].tolist()\n    print(f\"Selected {k} features:\")\n    print(selected_features)\n\n    # 3.2 Train XGBoost on selected features\n    model = XGBClassifier(\n        n_estimators=500,\n        learning_rate=0.05,\n        max_depth=6,\n        subsample=0.9,\n        colsample_bytree=0.9,\n        objective=\"binary:logistic\",\n        use_label_encoder=False,   # avoid label encoder warning\n        eval_metric=\"logloss\",\n        random_state=42,\n        n_jobs=-1\n    )\n\n    model.fit(X_train_k, y_train)\n\n    # 3.3 Evaluate on test set\n    y_pred = model.predict(X_test_k)\n\n    acc = accuracy_score(y_test, y_pred)\n    prec = precision_score(y_test, y_pred, zero_division=0)\n    rec = recall_score(y_test, y_pred, zero_division=0)\n    f1 = f1_score(y_test, y_pred, zero_division=0)\n\n    print(f\"Test Accuracy : {acc:.6f}\")\n    print(f\"Precision     : {prec:.6f}\")\n    print(f\"Recall        : {rec:.6f}\")\n    print(f\"F1 Score      : {f1:.6f}\")\n\n    # store results for later comparison\n    results_chi2[k] = {\n        \"features\": selected_features,\n        \"acc\": acc,\n        \"prec\": prec,\n        \"rec\": rec,\n        \"f1\": f1\n    }\n\nprint(\"\\n=========== SUMMARY: Chi-Square + XGBoost ===========\")\nfor k, info in results_chi2.items():\n    print(f\"Top-{k} features -> F1={info['f1']:.6f}, Acc={info['acc']:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T18:20:35.284959Z","iopub.execute_input":"2025-12-10T18:20:35.285323Z","iopub.status.idle":"2025-12-10T18:20:45.312322Z","shell.execute_reply.started":"2025-12-10T18:20:35.285290Z","shell.execute_reply":"2025-12-10T18:20:45.311059Z"}},"outputs":[{"name":"stdout","text":"Original dimension: 77\n\n============================================================\nCHI-SQUARE + XGBoost with top-5 features\n============================================================\nSelected 5 features:\n['Fwd Packet Length Min', 'Packet Length Min', 'URG Flag Count', 'CWE Flag Count', 'Avg Fwd Segment Size']\nTest Accuracy : 0.967400\nPrecision     : 0.945907\nRecall        : 0.991500\nF1 Score      : 0.968167\n\n============================================================\nCHI-SQUARE + XGBoost with top-10 features\n============================================================\nSelected 10 features:\n['Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Flow Bytes/s', 'Fwd PSH Flags', 'Packet Length Min', 'RST Flag Count', 'URG Flag Count', 'CWE Flag Count', 'Avg Packet Size', 'Avg Fwd Segment Size']\nTest Accuracy : 0.970700\nPrecision     : 0.947178\nRecall        : 0.997000\nF1 Score      : 0.971451\n\n============================================================\nCHI-SQUARE + XGBoost with top-15 features\n============================================================\nSelected 15 features:\n['Protocol', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Flow Bytes/s', 'Flow Packets/s', 'Fwd PSH Flags', 'Fwd Packets/s', 'Packet Length Min', 'Packet Length Mean', 'RST Flag Count', 'URG Flag Count', 'CWE Flag Count', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Init Fwd Win Bytes']\nTest Accuracy : 0.998550\nPrecision     : 0.998899\nRecall        : 0.998200\nF1 Score      : 0.998549\n\n============================================================\nCHI-SQUARE + XGBoost with top-20 features\n============================================================\nSelected 20 features:\n['Protocol', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Bwd Packet Length Min', 'Flow Bytes/s', 'Flow Packets/s', 'Bwd IAT Total', 'Fwd PSH Flags', 'Fwd Packets/s', 'Packet Length Min', 'Packet Length Mean', 'RST Flag Count', 'URG Flag Count', 'CWE Flag Count', 'Down/Up Ratio', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes']\nTest Accuracy : 0.998900\nPrecision     : 0.999399\nRecall        : 0.998400\nF1 Score      : 0.998899\n\n============================================================\nCHI-SQUARE + XGBoost with top-16 features\n============================================================\nSelected 16 features:\n['Protocol', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Flow Bytes/s', 'Flow Packets/s', 'Fwd PSH Flags', 'Fwd Packets/s', 'Packet Length Min', 'Packet Length Mean', 'RST Flag Count', 'URG Flag Count', 'CWE Flag Count', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes']\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/252203929.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# 3.3 Evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1517\u001b[0m             )\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1519\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1520\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             _check_call(\n\u001b[0;32m-> 2051\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2052\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m                 )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":30}]}