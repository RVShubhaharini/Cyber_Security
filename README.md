Cybersecurity: DDoS Attack Detection using Hybrid Nature-Inspired Feature Selection
Overview
Distributed Denial of Service (DDoS) attacks pose a serious threat to modern networked systems by overwhelming resources and disrupting legitimate services.
This repository accompanies the journal paper:
“A Hybrid Nature-Inspired Feature Selection Framework with Human Learning Optimization for Intrusion Detection and Cross-Domain Classification” 
The work proposes a multi-stage hybrid feature selection framework designed to improve DDoS and intrusion detection accuracy while significantly reducing feature dimensionality and computational cost.

Research Objectives
Design a robust hybrid feature selection framework for intrusion detection
Mitigate limitations of single-optimizer approaches (bias, premature convergence)
Improve DDoS detection accuracy with reduced feature sets
Validate the framework across cybersecurity and non-security domains
Demonstrate scalability for high-dimensional datasets

Proposed Framework
The proposed methodology integrates:
Global Optimization (Exploration)
Particle Swarm Optimization (PSO)
Genetic Algorithm (GA)
Grey Wolf Optimizer (GWO)

Ensemble Consensus Strategies
Union
Intersection
Majority Voting

These strategies consolidate diverse feature subsets generated by different optimizers.
Adaptive Refinement
Human Learning Optimization (HLO)
Greedy Hill-Climbing Local Search

Classification
XGBoost classifier for feature evaluation and final prediction
This hybrid design ensures global exploration + local optimality, making it highly effective for intrusion detection tasks.

Datasets Used
Cybersecurity Datasets
CSE-CIC-IDS 2018
CIC-DDoS 2019
Cross-Domain Validation Datasets
Weather Prediction Dataset
Heart Attack Risk Dataset
Loan Approval Dataset
The inclusion of non-security datasets demonstrates the domain-independent nature of the proposed framework.

Performance Highlights
Up to 90% feature reduction
F1-score reaching 0.9994
Improved accuracy compared to:

Filter-based methods (PCA, Chi-Square, Mutual Information)
Wrapper methods (RFE)
Embedded methods (LASSO, XGBoost feature importance)
Robust performance under class imbalance 

Technologies & Tools
Programming Language: Python
Optimization Techniques: PSO, GA, GWO, HLO
Machine Learning: XGBoost

Libraries:
NumPy
Pandas
Scikit-learn
XGBoost
Matplotlib / Seaborn
Environment: Jupyter Notebook / Python Scripts

Key Contributions
Novel multi-optimizer ensemble feature selection
Automated consensus-based feature aggregation
Two-stage refinement using Human Learning Optimization + hill climbing
Cross-domain generalization beyond cybersecurity datasets
Significant dimensionality reduction with high detection accuracy
